{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 From neural networks to deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar=datasets.CIFAR10('../../data/cifar10/',train=True,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar.train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(cifar.train_data)[43].transpose(2, 0).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 99,  98, 100,  ..., 129, 132, 130],\n",
       "         [100, 100, 102,  ..., 122, 135, 132],\n",
       "         [104, 104, 106,  ..., 165, 149, 140],\n",
       "         ...,\n",
       "         [195, 199, 221,  ..., 209, 209, 208],\n",
       "         [197, 201, 211,  ..., 208, 210, 209],\n",
       "         [199, 197, 204,  ..., 208, 210, 209]],\n",
       "\n",
       "        [[166, 165, 167,  ..., 186, 190, 188],\n",
       "         [166, 164, 167,  ..., 152, 189, 188],\n",
       "         [169, 167, 170,  ..., 165, 189, 189],\n",
       "         ...,\n",
       "         [173, 177, 194,  ..., 191, 190, 188],\n",
       "         [173, 178, 184,  ..., 190, 191, 191],\n",
       "         [173, 172, 174,  ..., 189, 191, 190]],\n",
       "\n",
       "        [[198, 196, 199,  ..., 212, 215, 213],\n",
       "         [195, 194, 197,  ..., 169, 213, 214],\n",
       "         [197, 195, 198,  ..., 160, 205, 212],\n",
       "         ...,\n",
       "         [149, 153, 166,  ..., 169, 171, 173],\n",
       "         [149, 149, 147,  ..., 171, 173, 175],\n",
       "         [149, 144, 137,  ..., 174, 177, 175]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 99,  98, 100, 103, 105, 107, 108, 110],\n",
       "         [100, 100, 102, 105, 107, 109, 110, 112],\n",
       "         [104, 104, 106, 109, 111, 112, 114, 116],\n",
       "         [109, 109, 111, 113, 116, 117, 118, 120]],\n",
       "\n",
       "        [[166, 165, 167, 169, 171, 172, 173, 175],\n",
       "         [166, 164, 167, 169, 169, 171, 172, 174],\n",
       "         [169, 167, 170, 171, 171, 173, 174, 176],\n",
       "         [170, 169, 172, 173, 175, 176, 177, 178]],\n",
       "\n",
       "        [[198, 196, 199, 200, 200, 202, 203, 204],\n",
       "         [195, 194, 197, 197, 197, 199, 200, 201],\n",
       "         [197, 195, 198, 198, 198, 199, 201, 202],\n",
       "         [197, 196, 199, 198, 198, 199, 200, 201]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,:4,:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Tensor basics and linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.empty(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  8.5899e+09, -2.0898e+10, -4.6577e-10,  4.2039e-45],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1250, 1.1250, 1.1250, 1.1250, 1.1250],\n",
       "        [1.1250, 1.1250, 1.1250, 1.1250, 1.1250]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.fill_(1.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1250)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.2500)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.25"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In-place operations are suﬃxed with an underscore, and a 0d tensor can be converted back to a Python scalar with item().替换原有位置内容时需要加下划线后缀，另外，想要得到0d张量的值可以加item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[11., 12., 13.], [21., 22., 23.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 12., 13.],\n",
       "        [21., 22., 23.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(23.)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([ 10., 20., 30.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([ 11., 21., 31.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21., 41., 61.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([110., 420., 930.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([100., 400., 900.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor([[ 0., 0., 3. ], \n",
    "                  [ 0., 2., 0. ], \n",
    "                  [ 1., 0., 0. ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 3.],\n",
       "        [0., 2., 0.],\n",
       "        [1., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([90., 40., 10.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.mv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([90., 40., 10.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m@x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.empty(2,4).random_(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 7., 5.],\n",
       "        [8., 2., 1., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 7., 5.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 7., 5.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 8.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:,1:3]=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., -1., -1.,  5.],\n",
       "        [ 8., -1., -1.,  0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.empty(3).normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2279, -0.3883, -1.1328])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.empty(3, 3).normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6266,  0.7976, -1.5173],\n",
       "        [ 0.0264,  0.5165,  1.6038],\n",
       "        [-0.4004, -1.1836,  0.2732]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "q,_ = torch.gels(y,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6058],\n",
       "        [ 0.6460],\n",
       "        [-0.4601]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2279],\n",
       "        [-0.3883],\n",
       "        [-1.1328]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(m,q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=torch.from_numpy(np.loadtxt('../../data/systolic-blood-pressure-vs-age.dat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = data.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = torch.empty(nb_samples, 2), torch.empty(nb_samples, 1) \n",
    "x[:, 0] = data[:, 0] \n",
    "x[:, 1] = 1 #对应偏置项bias\n",
    "y[:, 0] = data[:, 1] \n",
    "alpha, _ = torch.gels(y, x) \n",
    "a, b = alpha[0, 0].item(), alpha[1, 0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha.size()  ## 关于得到的alpha仍有疑问？？？？？？？？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9708701968193054"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.71473693847656"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis_val = torch.linspace(10, 80, 61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data[:,0].numpy(),data[:,1].numpy())\n",
    "\n",
    "plt.plot(x_axis_val.numpy(),(a*x_axis_val+b).numpy(),'r')\n",
    "\n",
    "plt.title(\"Linear Regression model\")\n",
    "\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"blood pressure\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 High dimension tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype, x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int64, device(type='cpu'))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype, x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([ [ 1, 3, 0 ], [ 2, 4, 6 ] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3, 0],\n",
       "        [2, 4, 6]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [0, 6]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 0, 2, 4, 6])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3],\n",
       "        [0, 2],\n",
       "        [4, 6]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(3,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 0],\n",
       "        [4, 6]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.narrow(1, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 3, 0],\n",
       "         [2, 4, 6]],\n",
       "\n",
       "        [[1, 3, 0],\n",
       "         [2, 4, 6]],\n",
       "\n",
       "        [[1, 3, 0],\n",
       "         [2, 4, 6]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(1, 2, 3).expand(3, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor torch.Size([50000, 3, 32, 32]) 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.from_numpy(cifar.train_data).transpose(1, 3).transpose(2, 3).float() \n",
    "x = x / 255 \n",
    "print(x.type(), x.size(), x.min().item(), x.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.narrow(0, 0, 48).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48, 3, 32, 32])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves these samples as a single image\n",
    "torchvision.utils.save_image(x, 'cifar-4x12.png', nrow = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switches the row and column indexes\n",
    "x.transpose_(2, 3)\n",
    "torchvision.utils.save_image(x, 'cifar-4x12-rotated.png', nrow = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kills the green and blue channels\n",
    "x.narrow(1, 1, 2).fill_(0) \n",
    "torchvision.utils.save_image(x, 'cifar-4x12-rotated-and-red.png', nrow = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.empty(100, 4).normal_(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5958e+00,  2.7524e+00,  1.1340e+00,  1.2731e+00],\n",
       "        [ 5.7326e-01,  1.2060e+00,  2.1322e+00,  1.3145e+00],\n",
       "        [ 3.0499e+00,  1.4494e+00,  1.5851e+00,  2.5536e+00],\n",
       "        [ 2.4011e+00,  2.4124e+00,  1.1996e+00,  1.7461e+00],\n",
       "        [ 1.8029e+00,  1.4859e+00,  3.0426e+00,  1.8921e+00],\n",
       "        [ 1.5584e+00,  2.5278e+00,  2.6250e+00,  2.7476e+00],\n",
       "        [ 1.6096e+00,  1.7482e+00,  1.0346e+00,  2.6046e+00],\n",
       "        [ 4.2126e+00,  2.0042e+00,  3.0465e+00,  3.0790e+00],\n",
       "        [ 1.3466e+00, -5.5563e-02,  1.7909e+00,  1.2956e+00],\n",
       "        [ 4.4208e+00,  2.8081e+00,  2.2109e+00,  9.0314e-02],\n",
       "        [ 1.8224e+00,  2.3072e+00,  1.5227e+00,  9.4121e-01],\n",
       "        [ 1.4449e+00,  2.3079e+00,  2.1993e+00,  2.9672e+00],\n",
       "        [ 2.3610e+00,  1.5181e+00,  2.7345e+00,  1.0338e+00],\n",
       "        [ 1.6533e+00,  3.1722e+00,  2.0301e+00,  2.3236e+00],\n",
       "        [ 1.4927e+00,  1.5535e+00,  1.8823e+00,  1.8365e+00],\n",
       "        [ 1.6430e+00,  7.7188e-01,  1.4716e+00,  1.6326e+00],\n",
       "        [ 1.2567e+00,  2.4396e+00,  7.9234e-01,  1.1798e+00],\n",
       "        [ 1.5307e+00,  3.5890e+00,  2.4953e+00,  2.4146e+00],\n",
       "        [ 6.1424e-01,  3.6148e+00,  1.5341e-01,  3.6311e+00],\n",
       "        [ 2.0835e+00,  2.5872e+00,  1.5647e+00,  4.0020e+00],\n",
       "        [ 2.6677e+00,  2.7851e+00,  1.4609e+00,  3.0194e+00],\n",
       "        [ 2.0655e+00,  2.2577e+00,  2.3746e+00,  3.1133e+00],\n",
       "        [ 2.5573e-01,  8.8756e-01,  1.0143e+00,  1.5372e+00],\n",
       "        [ 3.8989e+00,  2.5242e+00,  2.7180e+00,  8.6990e-01],\n",
       "        [ 2.0909e+00,  3.1871e+00,  3.0899e+00,  2.0297e+00],\n",
       "        [ 1.6349e+00,  2.1529e+00,  1.3647e+00,  1.2597e+00],\n",
       "        [ 2.3229e+00,  1.8685e+00,  1.6379e+00,  1.5994e+00],\n",
       "        [ 2.5012e+00,  1.0257e+00,  1.3633e+00,  4.1489e+00],\n",
       "        [ 2.5115e+00,  1.1232e+00,  2.1014e+00,  3.3628e+00],\n",
       "        [ 2.1271e+00, -2.1907e-01,  2.6483e+00,  1.2553e+00],\n",
       "        [ 1.7897e+00,  6.7254e-01,  2.2768e+00, -2.9018e-01],\n",
       "        [ 1.5205e-01,  1.2918e+00,  1.3005e+00,  2.7968e+00],\n",
       "        [ 2.0633e+00,  1.4812e+00,  2.5486e+00,  3.2737e+00],\n",
       "        [ 3.3896e+00,  1.1356e+00,  3.1407e+00,  3.3620e+00],\n",
       "        [ 2.4260e+00,  2.4770e+00,  2.5912e+00,  2.6444e+00],\n",
       "        [ 2.7607e+00,  2.8030e+00,  1.6046e+00,  1.8036e+00],\n",
       "        [ 2.3242e+00,  3.2169e+00,  3.5480e+00,  3.6773e+00],\n",
       "        [-1.5875e-01,  1.6952e+00,  3.0614e+00,  1.1608e+00],\n",
       "        [ 2.8677e+00,  2.2994e+00,  1.1735e+00,  1.5291e+00],\n",
       "        [ 4.6195e-01,  3.9058e+00,  1.4785e+00,  1.9268e+00],\n",
       "        [ 2.8565e+00,  1.6762e+00,  1.3119e+00,  2.8172e+00],\n",
       "        [ 1.6674e+00,  3.6994e-01,  2.0831e+00,  2.8424e+00],\n",
       "        [ 1.5284e+00,  2.2727e+00,  3.1604e+00, -4.4162e-01],\n",
       "        [ 2.0757e+00, -2.6783e-01,  2.7223e+00,  1.7910e+00],\n",
       "        [ 6.3631e-01,  5.5028e-01,  2.9044e+00,  1.0821e+00],\n",
       "        [ 1.8176e+00,  4.3178e+00,  3.6891e+00,  2.0094e+00],\n",
       "        [ 2.7952e+00,  4.5016e+00,  1.4280e+00,  1.4152e+00],\n",
       "        [ 8.1606e-01,  2.8205e+00,  5.1817e-01,  1.3365e+00],\n",
       "        [ 2.6222e+00,  2.1044e+00,  1.8762e+00,  2.4296e+00],\n",
       "        [ 1.2586e+00,  6.7064e-01,  3.0542e+00,  1.9760e+00],\n",
       "        [ 1.4992e+00,  1.1970e+00,  2.2687e+00,  2.8804e+00],\n",
       "        [ 2.9524e+00,  2.1727e+00,  3.5842e+00,  4.1674e+00],\n",
       "        [ 2.6143e+00,  2.1348e+00,  2.4921e+00,  2.2230e+00],\n",
       "        [ 1.4142e+00,  2.3961e+00,  9.5419e-01,  9.3618e-01],\n",
       "        [ 7.4421e-01,  2.9349e+00,  2.0512e+00,  2.1684e+00],\n",
       "        [ 2.3526e+00,  4.1312e+00,  1.1486e+00,  3.1420e-01],\n",
       "        [ 1.5330e+00,  3.4134e+00,  2.6890e+00,  2.3895e+00],\n",
       "        [ 4.3178e+00,  2.7159e+00,  1.8256e+00,  3.1851e+00],\n",
       "        [ 1.2136e-01,  1.1446e+00,  1.1097e+00,  1.2119e+00],\n",
       "        [ 3.3493e+00,  8.3092e-01,  3.6063e+00,  1.8185e+00],\n",
       "        [ 2.5771e+00,  9.5591e-01,  1.5692e+00,  1.3933e+00],\n",
       "        [ 1.4568e+00,  1.7958e+00,  1.6125e+00,  8.6126e-01],\n",
       "        [ 7.1037e-01,  2.7793e+00,  1.7597e+00,  2.2517e+00],\n",
       "        [ 1.4044e+00,  2.8196e+00,  2.6881e+00,  2.2563e+00],\n",
       "        [ 3.1410e+00,  2.1827e+00,  2.4538e+00,  2.8766e+00],\n",
       "        [ 9.6079e-01,  1.1696e+00,  1.3340e+00,  1.5167e+00],\n",
       "        [ 1.7250e+00,  1.5771e+00,  7.8263e-01,  1.2843e+00],\n",
       "        [ 6.7802e-01,  9.0388e-01,  2.2982e+00,  8.2690e-01],\n",
       "        [ 2.1634e+00,  2.0215e+00,  9.9340e-01,  1.1349e+00],\n",
       "        [ 2.3014e+00,  2.6035e+00,  2.2355e+00,  1.6991e+00],\n",
       "        [ 2.1847e+00,  2.1962e+00,  1.2946e+00, -1.0386e-01],\n",
       "        [ 2.7187e+00,  2.6662e+00,  7.8417e-01,  3.1839e+00],\n",
       "        [ 4.4001e-03,  3.3671e+00,  2.3473e+00,  2.6786e+00],\n",
       "        [ 3.6703e+00,  1.1687e+00,  1.4697e+00,  2.1233e+00],\n",
       "        [ 2.6570e+00,  1.9246e+00,  1.0980e+00,  1.5780e+00],\n",
       "        [ 2.4004e+00,  6.6943e-01,  1.3670e+00,  8.7148e-01],\n",
       "        [ 1.7180e+00,  2.7257e+00,  2.1720e+00,  1.9348e+00],\n",
       "        [ 1.4334e+00,  1.9472e+00,  1.9635e+00,  1.0063e+00],\n",
       "        [ 2.8893e+00,  1.3094e+00,  2.2530e+00,  2.0905e+00],\n",
       "        [ 1.8713e+00,  1.8720e+00,  2.4549e+00,  2.4795e+00],\n",
       "        [ 2.6144e+00,  2.0315e+00,  1.1017e+00,  2.1437e+00],\n",
       "        [ 1.9548e+00,  2.2740e+00,  3.1651e+00,  2.2255e+00],\n",
       "        [ 1.3612e+00,  2.0050e+00,  1.8953e+00,  1.6270e+00],\n",
       "        [ 2.9024e+00,  1.5654e+00,  3.1493e+00,  1.3145e+00],\n",
       "        [ 6.5439e-01,  1.5942e+00,  1.5333e+00,  1.9134e+00],\n",
       "        [ 2.3035e+00,  1.1753e+00,  2.8645e+00,  3.5151e+00],\n",
       "        [ 2.2552e+00,  3.1464e+00,  1.6571e+00,  2.6190e+00],\n",
       "        [ 2.2520e+00,  1.3420e+00,  7.5467e-01,  1.9725e+00],\n",
       "        [ 2.5553e+00,  2.1203e+00,  2.0938e+00,  3.5137e+00],\n",
       "        [ 1.2673e+00,  2.5377e+00,  2.8871e+00,  2.9048e+00],\n",
       "        [ 2.3478e+00,  2.6363e+00,  1.9680e+00,  2.3430e+00],\n",
       "        [ 1.8480e+00,  2.4666e+00,  3.1046e+00,  2.6116e+00],\n",
       "        [ 1.7327e+00,  9.2885e-01,  1.1693e+00, -8.8536e-02],\n",
       "        [ 2.8608e+00,  1.9855e+00,  3.4070e+00,  1.9984e+00],\n",
       "        [-4.0406e-01,  2.8320e+00,  3.2644e-01, -1.5169e-01],\n",
       "        [ 2.6199e+00,  3.7835e+00,  1.5375e+00,  3.0942e+00],\n",
       "        [ 1.8817e+00,  1.7717e+00,  1.6716e+00,  3.4997e+00],\n",
       "        [ 2.7468e+00,  3.1097e+00,  1.9814e+00,  2.6197e+00],\n",
       "        [ 3.3630e+00,  1.9099e+00,  3.4749e+00,  1.6752e+00],\n",
       "        [ 2.1144e+00,  3.1445e+00,  1.3048e+00,  2.7832e-01]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.9750, 2.0588, 1.9960, 1.9876])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x -= x.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.7299e-07,  1.7285e-07, -7.1526e-08, -4.4942e-07])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([[1.], [2.], [3.], [4.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = torch.tensor([[5., -5., 5., -5., 5.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5., -5.,  5., -5.,  5.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=A+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6., -4.,  6., -4.,  6.],\n",
       "        [ 7., -3.,  7., -3.,  7.],\n",
       "        [ 8., -2.,  8., -2.,  8.],\n",
       "        [ 9., -1.,  9., -1.,  9.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Tensor internals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       "[torch.FloatStorage of size 8]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = x.storage()\n",
    "q[4] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.view(2, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[1., 0.],\n",
       "         [0., 0.]]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[1, 1, 0] = 7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [1., 0., 7., 0.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3., 3.],\n",
       "         [3., 3.]]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.narrow(0, 1, 1).fill_(3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of data type 6 but got data type 4 for argument #2 'source'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-b65c4fe76838>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of data type 6 but got data type 4 for argument #2 'source'"
     ]
    }
   ],
   "source": [
    "q = torch.arange(0, 20).storage()\n",
    "x = torch.empty(0).set_(q, storage_offset = 5, size = (3, 2), stride = (4, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = torch.linspace(1, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3., 4.],\n",
       "        [2., 3., 4.],\n",
       "        [2., 3., 4.]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(0.).set_(n.storage(), 1, (3, 3), (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(0.).set_(n.storage(), 1, (2, 4), (1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.empty(100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Call .contiguous() before .view(). at /Users/administrator/nightlies/pytorch-1.0.0/wheel_build_dirs/wheel_3.6/pytorch/aten/src/TH/generic/THTensor.cpp:213",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-3bfc94341ca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Call .contiguous() before .view(). at /Users/administrator/nightlies/pytorch-1.0.0/wheel_build_dirs/wheel_3.6/pytorch/aten/src/TH/generic/THTensor.cpp:213"
     ]
    }
   ],
   "source": [
    "y.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
